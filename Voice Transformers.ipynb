{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9b0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import seaborn as sb\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import json\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adc75f",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcc13fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"D:/Urdu_Voice/data.json\"\n",
    "\n",
    "def load_data(data_path):\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    x = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    \n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  x, y\n",
    "\n",
    "x, y = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac6fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b475e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, validation_size):\n",
    "    \n",
    "    X, y = load_data(DATA_PATH)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    #X_train = X_train[..., np.newaxis]\n",
    "    #X_validation = X_validation[..., np.newaxis]\n",
    "    #X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ffa070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a194e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
